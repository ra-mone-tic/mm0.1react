# scrape_vk.py  â–¸  Python 3.10+
import re, time, requests, pandas as pd
from geopy.geocoders import ArcGIS
from geopy.extra.rate_limiter import RateLimiter

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOKEN        = "vk1.a.az68uTKtqRoSRW7ud6qQBHBYEDX-IoB3n-raywQhtxBEfNEsIncINjLHPtxM6GA0lLaf_FjOY9H89xHnTq3c65AtgZzZ4BNxzgC8ThX56PY52S8yf3cZxbS4Utojhi83OiCUofSgsuBRXJldpIHtzuO70BBV8wR1DM9bdSMUhknZ7kb1e6ib9XBG2vnJSjXjhQ76en7c7VDcIMv-PqeCfQ"   # â† Ğ²ÑÑ‚Ğ°Ğ²ÑŒ ÑĞ²Ğ¾Ğ¹
DOMAIN       = "meowrecords"       # Ğ¿Ğ°Ğ±Ğ»Ğ¸Ğº Ğ’Ğš
MAX_POSTS    = 2000                # ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²ÑĞµĞ³Ğ¾ Ñ‚ÑĞ½ÑƒÑ‚ÑŒ (offsetâ€™Ğ°Ğ¼Ğ¸)
BATCH        = 100                 # Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ Ğ·Ğ° 1 Ğ²Ñ‹Ğ·Ğ¾Ğ² API
WAIT_REQ     = 1.1                 # Ğ¿Ğ°ÑƒĞ·Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ°Ğ¼Ğ¸ wall.get  (1 rps)
WAIT_GEO     = 1.0                 # Ğ¿Ğ°ÑƒĞ·Ğ° ArcGIS                 (â‰ˆ1000/ÑÑƒÑ‚ĞºĞ¸)
YEAR_DEFAULT = "2025"              # Ğ´Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğº dd.mm

geo = RateLimiter(ArcGIS(timeout=10).geocode, min_delay_seconds=WAIT_GEO)
vk  = "https://api.vk.com/method/wall.get"

def vk_wall(offset: int):
    params = dict(domain=DOMAIN, offset=offset, count=BATCH,
                  access_token=TOKEN, v="5.199")
    return requests.get(vk, params=params, timeout=15).json()["response"]["items"]

def extract(text: str):
    m_date = re.search(r"\b(\d{2})\.(\d{2})\b", text)
    m_loc  = re.search(r"ğŸ“\s*(.+)", text)
    if not (m_date and m_loc):
        return None
    date  = f"{YEAR_DEFAULT}-{m_date.group(2)}-{m_date.group(1)}"
    loc   = m_loc.group(1).split('â¡ï¸')[0].strip()
    if not re.search(r"(ĞºĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´|Ğ³ÑƒÑ€ÑŒĞµĞ²ÑĞº|ÑĞ²ĞµÑ‚Ğ»Ğ¾Ğ³Ğ¾Ñ€ÑĞº|ÑĞ½Ñ‚Ğ°Ñ€Ğ½Ñ‹Ğ¹)", loc, re.I):
        loc += ", ĞšĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´"
    title = re.sub(r"^\d{2}\.\d{2}\s*\|\s*", "", text.split('\n')[0]).strip()
    return dict(title=title, date=date, location=loc)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ğ¡Ğ‘ĞĞ  ĞŸĞĞ¡Ğ¢ĞĞ’ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
records, off = [], 0
while off < MAX_POSTS:
    items = vk_wall(off)
    if not items: break
    for it in items:
        evt = extract(it["text"])
        if evt: records.append(evt)
    off += BATCH
    time.sleep(WAIT_REQ)

print("ĞĞ½Ğ¾Ğ½ÑĞ¾Ğ² Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾:", len(records))
df = pd.DataFrame(records).drop_duplicates()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ğ“Ğ•ĞĞšĞĞ”Ğ˜ĞĞ“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def to_latlon(addr: str):
    try:
        g = geo(addr)
        return (g.latitude, g.longitude) if g else (None, None)
    except: return (None, None)

df[["lat", "lon"]] = df["location"].apply(lambda a: pd.Series(to_latlon(a)))
bad_cnt = df["lat"].isna().sum()
df = df.dropna(subset=["lat", "lon"])

print(f"Ğ¡ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ°Ğ¼Ğ¸: {len(df)} | Ğ±ĞµĞ· ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚: {bad_cnt}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ğ¡ĞĞ¥Ğ ĞĞĞ¯Ğ•Ğœ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df[["title","date","location","lat","lon"]].to_json(
    "events.json", orient="records", force_ascii=False, indent=2)
print("âœ…  events.json ÑĞ¾Ğ·Ğ´Ğ°Ğ½")